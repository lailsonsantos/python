{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YiG1TTPeNoWi"
   },
   "outputs": [],
   "source": [
    "#Universidade de Pernambuco (UPE)\n",
    "#Escola Politecnica de Pernambuco (Poli)\n",
    "#Curso de Especializacao em Ciencia dos Dados e Analytics\n",
    "#Disciplina de Solucoes em Mineracao de dados\n",
    "#--------------------------------------------------------\n",
    "#Script para tratamentos de valores ausentes\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "# Importando as bibliotecas necessarias\n",
    "import pandas\n",
    "import scipy\n",
    "import numpy\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "\n",
    "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
    "print(dataset.shape)\n",
    "\n",
    "print(\"Conhecendo os dados estatisticos dos dados carregados (describe)\")\n",
    "print(dataset.describe())\n",
    "\n",
    "print(\"Visualizando o conjunto inicial (head) dos dados, ou mais claramente\"\n",
    "\t\t\"os 20 primeiros registros (head(20))\")\n",
    "print(dataset.head(20))\n",
    "\n",
    "print(\"Quantidade de pontos que possue 0 como valor\")\n",
    "print((dataset[[1,2,3,4,5]] == 0).sum())\n",
    "\n",
    "# Marcar os valores ausentes como NaN\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, numpy.NaN)\n",
    "\n",
    "print(\"Realiza a contagem de valores NaN em cada coluna\")\n",
    "print(dataset.isnull().sum())\n",
    "\n",
    "print(\"Visualizando o conjunto inicial (head) dos dados, ou mais claramente\"\n",
    "\t\t\"os 20 primeiros registros (head(20))\")\n",
    "print(dataset.head(20)) \n",
    "\n",
    "#Abordagems para substituicao do NaN\n",
    "#usando a media (mean) mediana (median) coluna por coluna\n",
    "#dataset[4].fillna(dataset[4].median(), inplace=True)\n",
    "\n",
    "#preenchendo com as ocorrencias mais pr√≥ximas\n",
    "#dataset.fillna(method='ffill',inplace=True)\n",
    "\n",
    "# Removendo registros que possuem valores ausentes (NaN)\n",
    "#dataset.dropna(inplace=True)\n",
    "\n",
    "# Preenchendo os valores ausentes com base na media dos valores da coluna\n",
    "# existe ainda as opcoes via mediana e valores mais frequentes\n",
    "dataset.fillna(dataset.mean(), inplace=True)\n",
    "\n",
    "#fazendo interpolacao para encontrar os novos valores para NaN\n",
    "#dataset=dataset.interpolate()\n",
    "\n",
    "print(\"Mostra a quantidade de valores ausentes (NaN) de cada coluna\")\n",
    "print(dataset.isnull().sum())\n",
    "print(dataset.shape)\n",
    "\n",
    "print(\"Visualizando o conjunto inicial (head) dos dados, ou mais claramente\"\n",
    "\t\t\"os 20 primeiros registros (head(20))\")\n",
    "print(dataset.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZkFAkyGTbPro"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Realizando a remocao de valores aberrantes de atributos\n",
    "\n",
    "\n",
    "#Utilizando a base de dados com caracteristicas de carros\n",
    "dataset = pd.read_csv('/content/mtcars.csv')\n",
    "\n",
    "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
    "print(dataset.shape)\n",
    "\n",
    "print(\"Conhecendo os dados estatisticos dos dados carregados (describe)\")\n",
    "print(dataset.describe())\n",
    "\n",
    "print('Apresentando os primeiros registros')\n",
    "print(dataset.head())\n",
    "\n",
    "#Gerando boxplot para a caracteristia HP\n",
    "sns.boxplot(data=dataset,x=dataset['hp'])\n",
    "\n",
    "#obtendo o valor do Q1\n",
    "Q1=dataset['hp'].quantile(0.25)\n",
    "\n",
    "#obtendo o valor do Q3\n",
    "Q3=dataset['hp'].quantile(0.75)\n",
    "\n",
    "#obtendo a faixa de valores interquartil\n",
    "IQR=Q3-Q1\n",
    "\n",
    "print(Q1)\n",
    "\n",
    "print(Q3)\n",
    "\n",
    "print(IQR)\n",
    "\n",
    "Lower_Whisker = Q1-1.5*IQR\n",
    "\n",
    "Upper_Whisker = Q3+1.5*IQR\n",
    "\n",
    "print(Lower_Whisker, Upper_Whisker)\n",
    "\n",
    "dataset = dataset[dataset['hp']< Upper_Whisker]\n",
    "\n",
    "print(\"Apresentando o shape dos dados (dimenssoes)\")\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "81e2ceXOijJ0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "#Realizando a discretizacao de atributos continuos\n",
    "#Create a DataFrame\n",
    "df1 = {\n",
    "    'Name':['George','Andrea','micheal','maggie','Ravi','Xien','Jalpa','Tyieren'],    \n",
    "    'Score':[63,48,56,75,32,77,85,22]\n",
    "     \n",
    "   }\n",
    " \n",
    " \n",
    "df1 = pd.DataFrame(df1,columns=['Name','Score'])\n",
    "print(df1)\n",
    "\n",
    "''' binning or bucketing with range'''\n",
    " \n",
    "bins = [0, 25, 50, 75, 100]\n",
    "df1['binned'] = pd.cut(df1['Score'], bins)\n",
    "print (df1)\n",
    "\n",
    "\n",
    "''' binning or bucketing with labels'''\n",
    " \n",
    "bins = [0, 25, 50, 75, 100]\n",
    "labels =[1,2,3,4]\n",
    "df1['binned'] = pd.cut(df1['Score'], bins,labels=labels)\n",
    "print (df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2szFGQPMlA1g"
   },
   "outputs": [],
   "source": [
    "#Universidade de Pernambuco (UPE)\n",
    "#Escola Politecnica de Pernambuco (Poli)\n",
    "#Curso de Especializacao em Ciencia dos Dados e Analytics\n",
    "#Disciplina de Solucoes em Mineracao de dados\n",
    "#--------------------------------------------------------\n",
    "#Script que padroniza os dados para media 0 e desvio 1\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "# Importando as bibliotecas necessarias\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#definindo os nomes de cada coluna\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "#Fazendo o carregamento dos dados diretamente do UCI Machine Learning          \n",
    "dataframe = pandas.read_csv('pima-indians-diabetes.csv', names=names)\n",
    "\n",
    "print(\"Dados originais\")\n",
    "print(dataframe.head(5))\n",
    "\n",
    "#separa os dados de entrada e saida\n",
    "array = dataframe.values\n",
    "X = array[:,0:8] #separa os dados da primeira coluna (0) ate a penultima (8)\n",
    "Y = array[:,8] #separa os dados da ultima coluna\n",
    "\n",
    "#padroniza os dados com media 0 e desvio 1\n",
    "scaler = StandardScaler().fit(X)\n",
    "rescaledX = scaler.transform(X)\n",
    "\n",
    "print(\"Resumo dos dados modificados\")\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(rescaledX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Un_Lwa9MlTYV",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dados originais\n   preg  plas  pres  skin  test  mass   pedi  age  class\n0     6   148    72    35     0  33.6  0.627   50      1\n1     1    85    66    29     0  26.6  0.351   31      0\n2     8   183    64     0     0  23.3  0.672   32      1\n3     1    89    66    23    94  28.1  0.167   21      0\n4     0   137    40    35   168  43.1  2.288   33      1\nResumo dos dados modificados\n[[0.034 0.828 0.403 0.196 0.    0.188 0.004 0.28 ]\n [0.008 0.716 0.556 0.244 0.    0.224 0.003 0.261]\n [0.04  0.924 0.323 0.    0.    0.118 0.003 0.162]\n [0.007 0.588 0.436 0.152 0.622 0.186 0.001 0.139]\n [0.    0.596 0.174 0.152 0.731 0.188 0.01  0.144]]\n"
    }
   ],
   "source": [
    "#Universidade de Pernambuco (UPE)\n",
    "#Escola Politecnica de Pernambuco (Poli)\n",
    "#Curso de Especializacao em Ciencia dos Dados e Analytics\n",
    "#Disciplina de Solucoes em Mineracao de dados\n",
    "#--------------------------------------------------------\n",
    "#Script para normalizacao dos dados\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "# Importando as bibliotecas necessarias\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#definindo os nomes de cada coluna\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "#Fazendo o carregamento dos dados diretamente do UCI Machine Learning          \n",
    "dataframe = pandas.read_csv('dados/pima-indians-diabetes.csv', names=names)\n",
    "\n",
    "print(\"Dados originais\")\n",
    "print(dataframe.head(5))\n",
    "\n",
    "#separa os dados de entrada e saida\n",
    "array = dataframe.values\n",
    "X = array[:,0:8] #separa os dados da primeira coluna (0) ate a penultima (8)\n",
    "Y = array[:,8] #separa os dados da ultima coluna\n",
    "\n",
    "#normaliza os dados\n",
    "scaler = Normalizer().fit(X)\n",
    "normalizedX = scaler.transform(X)\n",
    "\n",
    "print(\"Resumo dos dados modificados\")\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(normalizedX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C6KSAn0Plf67"
   },
   "outputs": [],
   "source": [
    "#Universidade de Pernambuco (UPE)\n",
    "#Escola Politecnica de Pernambuco (Poli)\n",
    "#Curso de Especializacao em Ciencia dos Dados e Analytics\n",
    "#Disciplina de Solucoes em Mineracao de dados\n",
    "#--------------------------------------------------------\n",
    "#Script para a binarizacao de dados\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "# Importando as bibliotecas necessarias\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "#definindo os nomes de cada coluna\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "#Fazendo o carregamento dos dados diretamente do UCI Machine Learning          \n",
    "dataframe = pandas.read_csv('pima-indians-diabetes.csv', names=names)\n",
    "\n",
    "print(\"Dados originais\")\n",
    "print(dataframe.head(5))\n",
    "\n",
    "#separa os dados de entrada e saida\n",
    "array = dataframe.values\n",
    "X = array[:,0:8] #separa os dados da primeira coluna (0) ate a penultima (8)\n",
    "Y = array[:,8] #separa os dados da ultima coluna\n",
    "\n",
    "binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "binaryX = binarizer.transform(X)\n",
    "\n",
    "print(\"Resumo dos dados modificados\")\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(binaryX[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mKjvkbW0liih"
   },
   "outputs": [],
   "source": [
    "#Universidade de Pernambuco (UPE)\n",
    "#Escola Politecnica de Pernambuco (Poli)\n",
    "#Curso de Especializacao em Ciencia dos Dados e Analytics\n",
    "#Disciplina de Solucoes em Mineracao de dados\n",
    "#--------------------------------------------------------\n",
    "#Script para re-escala de dados\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "# Importando as bibliotecas necessarias\n",
    "import pandas\n",
    "import scipy\n",
    "import numpy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import read_csv\n",
    "\n",
    "\n",
    "#definindo os nomes de cada coluna\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "#Fazendo o carregamento dos dados diretamente do UCI Machine Learning\n",
    "dataframe = read_csv('pima-indians-diabetes.csv', names=names)\n",
    "\n",
    "print(\"Dados originais\")\n",
    "print(dataframe.head(5))\n",
    "\n",
    "#separa os dados de entrada e saida\n",
    "array = dataframe.values\n",
    "X = array[:,0:8] #separa os dados da primeira coluna (0) ate a penultima (8)\n",
    "Y = array[:,8] #separa os dados da ultima coluna\n",
    "\n",
    "#realiza a re-escala dos dados\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataframe[['preg', 'plas']] = scaler.fit_transform(dataframe[['preg', 'plas']])\n",
    "rescaledX = scaler.fit_transform(X)\n",
    "\n",
    "print(\"Resumo dos dados modificadoss\")\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(rescaledX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohG9SMyiuom-"
   },
   "outputs": [],
   "source": [
    "2#Universidade de Pernambuco (UPE)\n",
    "#Escola Politecnica de Pernambuco (Poli)\n",
    "#Curso de Especializacao em Ciencia dos Dados e Analytics\n",
    "#Disciplina de Solucoes em Mineracao de dados\n",
    "#--------------------------------------------------------\n",
    "#Script para converter dados categoricos em binarios\n",
    "#--------------------------------------------------------\n",
    "\n",
    "\n",
    "# Importando as bibliotecas necessarias\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "# Define the headers since the data does not have any\n",
    "nomes = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
    "           \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\",\n",
    "           \"wheel_base\", \"length\", \"width\", \"height\", \"curb_weight\",\n",
    "           \"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\",\n",
    "           \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\",\n",
    "           \"city_mpg\", \"highway_mpg\", \"price\"]\n",
    "\n",
    "# Read in the CSV file and convert \"?\" to NaN\n",
    "df = pandas.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data',\n",
    "                  header=None, names=nomes, na_values=\"?\" )\n",
    "\n",
    "print(\"Dados originais\")\n",
    "print(df.head())\n",
    "\n",
    "print(df.dtypes) \n",
    "\n",
    "print(\"selecionar apenas as colunas que sao do tipo objeto/categorigos\")\n",
    "obj_df = df.select_dtypes(include=['object']).copy()\n",
    "print(obj_df.head())\n",
    "\n",
    "print(\"verificar a existencia de dados ausentes\")\n",
    "print(obj_df[obj_df.isnull().any(axis=1)])\n",
    "\n",
    "print(\"realiza a contagem de dados de um atributo\")\n",
    "print(obj_df[\"num_doors\"].value_counts())\n",
    "\n",
    "print(\"realiza o preenchimento NaN com um valor especifico\")\n",
    "obj_df = obj_df.fillna({\"num_doors\": \"four\"})\n",
    "\n",
    "#conversao de categorigo para binario\n",
    "print(pandas.get_dummies(obj_df, columns=[\"drive_wheels\"]).head())\n",
    "\n",
    "dfb = pandas.get_dummies(obj_df, columns=[\"drive_wheels\"]);\n",
    "\n",
    "print(pandas.get_dummies(dfb, columns=[\"body_style\"]).head())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Pre-processamento.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}